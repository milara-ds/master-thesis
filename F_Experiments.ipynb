{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Final: Experiments**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Read the datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dflist_areas = []\n",
    "areas = ['ingenieria', 'negocios','estudioscreativos', 'salud', 'cienciassociales', 'ambienteconstruido']\n",
    "\n",
    "for elem in areas:\n",
    "    df_area = pd.read_csv(\"C:/Users/Milara/..._\"+elem+\"_v1.csv\",encoding=\"ISO-8859-1\")\n",
    "    dflist_areas.append(df_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Remove variables not used (NaN removed)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_selected_features = pd.read_csv(\"C:/Users/Milara/...\",encoding=\"UTF-8\")\n",
    "\n",
    "#for i in range(len(areas)):\n",
    "#    all_features = df_selected_features[areas[i]].dropna().to_list()\n",
    "#    df_wo_na_all = dflist_areas[i][all_features].dropna()\n",
    "#    dflist_areas[i] = df_wo_na_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Create binary output (balanced classes)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(val,threshold):\n",
    "    if val < threshold:\n",
    "        return 0.0\n",
    "    elif val >= threshold:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "for elem in dflist_areas:\n",
    "    median = elem['For_Prom'].median()\n",
    "    level = elem['For_Prom'].apply(lambda x: update(x,median))\n",
    "    #Inserting the values in the df\n",
    "    elem.insert(elem.shape[1],'Binary_out',level.values)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Select variables based on dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_var(prefix,lista):\n",
    "    res = lista.copy()\n",
    "    for elem in prefix:\n",
    "        for i in range(len(lista)):\n",
    "            value = lista[i].find(elem)\n",
    "            if value >= 0:\n",
    "                res.remove(lista[i])\n",
    "    return res\n",
    "\n",
    "def keep_var(prefix,lista):\n",
    "    res = []\n",
    "    res.append(lista[-3]) # to add calpromedioprepa\n",
    "    for elem in prefix:\n",
    "        for i in range(len(lista)):\n",
    "            value = lista[i].find(elem)\n",
    "            if value >= 0:\n",
    "                res.append(lista[i])\n",
    "    res.append(lista[-2])\n",
    "    res.append(lista[-1])\n",
    "    return res\n",
    "\n",
    "def select_database(i, df): #requiere los nombres de las columnas en lista ..list_areas[0].columns.to_list()\n",
    "    features = df.columns.to_list()\n",
    "    if i == 0:\n",
    "        #Caso 0 ->  PAA\n",
    "        list_var = keep_var(['Puntaje'], features)\n",
    "    elif i == 1:\n",
    "        # Caso 1 ->  Eva\n",
    "        list_var = keep_var(['Eva'], features)\n",
    "    elif i == 2 :\n",
    "        # Caso 2 ->  Senti\n",
    "        list_var = keep_var(['_n'], features)\n",
    "    elif i == 3:\n",
    "        # Caso 3 -> Ord \n",
    "        list_var = keep_var(['_ord'], features)\n",
    "    elif i == 4:\n",
    "        # Caso 4 -> eval + paa\n",
    "        list_var = keep_var(['Eva','Puntaje'], features)\n",
    "    elif i == 5:\n",
    "        # Caso 5 -> eval + senti\n",
    "        list_var = keep_var(['Eva','_n'], features)\n",
    "    elif i == 6:\n",
    "        # Caso 6 -> eval + ord\n",
    "        list_var = keep_var(['Eva','_ord'], features)\n",
    "    elif i == 7:\n",
    "        # Caso 7 -> paa + senti\n",
    "        list_var = keep_var(['Puntaje','_n'], features)\n",
    "    elif i == 8:\n",
    "        # Caso 8 -> paa + ord\n",
    "        list_var = keep_var(['Puntaje','_ord'], features)\n",
    "    elif i == 9:\n",
    "        # Caso 9 -> senti + ord\n",
    "        list_var = keep_var(['_n','_ord'], features)\n",
    "    elif i == 10:\n",
    "        # Caso 10 -> eval + paa + senti\n",
    "        list_var = keep_var(['Eva','Puntaje','_n'], features)\n",
    "    elif i == 11:\n",
    "        # Caso 11 -> eval + paa + ord\n",
    "        list_var = keep_var(['Eva','Puntaje','_ord'], features)\n",
    "    elif i == 12:\n",
    "        # Caso 12 -> eval + senti + ord\n",
    "        list_var = keep_var(['Eva','_n','_ord'], features)\n",
    "    elif i == 13:\n",
    "        # Caso 13 -> paa + senti + ord\n",
    "        list_var = keep_var(['Puntaje','_n','_ord'], features)\n",
    "    elif i == 14:\n",
    "        # Caso 14 -> eval + paa + senti + ord\n",
    "        list_var = features\n",
    "    elif i == 15:\n",
    "        # Caso 14 -> eval without CalPrepa\n",
    "        list_var = keep_var(['Eva'], features)\n",
    "        list_var.remove('CalPromedioPrepa')\n",
    "    \n",
    "    list_var.remove('For_Prom')\n",
    "    \n",
    "    return df[list_var]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5 .Feature Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "def PCA_selection(df, corrThres): #requiere df sin NaN\n",
    "    all_features = df.columns.to_list()\n",
    "    scaled_data = preprocessing.scale(df.loc[:,all_features[:-1]])\n",
    "    pca = PCA()\n",
    "    pca.fit(scaled_data)\n",
    "    pca_data = pca.transform(scaled_data)\n",
    "    \n",
    "    per_var = np.round(pca.explained_variance_ratio_*100, decimals = 1)\n",
    "    labels = [ 'PC' + str(x) for x in range(1, len(per_var) +1 )]\n",
    "    pca_df_1 = pd.DataFrame(pca_data, index = df.loc[:,all_features[:-1]].index, columns = labels)\n",
    "    df_feat_pcs = pd.concat([df[all_features[:-1]],pca_df_1[['PC1']]], axis = 1)\n",
    "    corr = df_feat_pcs.corr()\n",
    "\n",
    "    #IMPORTANT CELL WHERE THE VARIABLES ARE SELECTED BASED ON THE ABS OF 0.5 FOR CORRELATION\n",
    "    corr_reduced = corr.loc[all_features[:-1]]\n",
    "    features = corr_reduced[(corr_reduced['PC1'] < -corrThres)  | (corr_reduced['PC1'] > corrThres)].sort_values(by ='PC1').index.to_list()\n",
    "    features.append(all_features[-1])\n",
    "    df_selected = df[features]\n",
    "    \n",
    "    return df_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Testing it*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1862 entries, 0 to 1861\n",
      "Data columns (total 6 columns):\n",
      "Eva_ini_UMM1    1862 non-null float64\n",
      "Eva_ini_UMM2    1862 non-null float64\n",
      "Eva_ini_UMF1    1862 non-null float64\n",
      "Eva_ini_UMF2    1862 non-null float64\n",
      "Eva_ini_UMC1    1862 non-null float64\n",
      "Binary_out      1862 non-null float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 87.4 KB\n"
     ]
    }
   ],
   "source": [
    "ing = dflist_areas[0].copy() #Select the area\n",
    "ing_red = select_database(15, ing) #Select the database\n",
    "ing_red.info()\n",
    "#ing_sel = PCA_selection(ing_red, 0.37) #Apply PCA Selection\n",
    "#ing_sel.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **T-test (only the variables where there is significant difference between the two groups)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "def Ttest_selection(df,levelSignificance):\n",
    "    df_red_1 = df[df['Binary_out'] == 1.0]\n",
    "    df_red_0 = df[df['Binary_out'] == 0.0]\n",
    "\n",
    "    features = df.columns.to_list()[:-1]\n",
    "    stat = []\n",
    "    pval = []\n",
    "\n",
    "    for elem in features:\n",
    "        stat.append(stats.ttest_ind(df_red_1[elem], df_red_0[elem], equal_var = False).statistic)\n",
    "        pval.append(round(stats.ttest_ind(df_red_1[elem], df_red_0[elem], equal_var = False).pvalue,5))\n",
    "\n",
    "    d = {'Feature': features, 'Statistic':stat , 'P-value':pval}\n",
    "    df_ttest = pd.DataFrame(data=d)\n",
    "    #print(df_ttest)\n",
    "    ordered = df_ttest.sort_values(by = 'Statistic', ascending = False)\n",
    "    significance = ordered[ordered['P-value'] < levelSignificance]\n",
    "    #print(significance)\n",
    "    sel_vars = significance['Feature'].to_list()\n",
    "    sel_vars.append('Binary_out')\n",
    "    \n",
    "    return(df[sel_vars])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Testing it*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1862 entries, 0 to 1861\n",
      "Data columns (total 9 columns):\n",
      "CalPromedioPrepa    1862 non-null float64\n",
      "Eva_ini_UMM1        1862 non-null float64\n",
      "Eva_ini_UMF1        1862 non-null float64\n",
      "Eva_ini_UMC1        1862 non-null float64\n",
      "Eva_ini_UMM2        1862 non-null float64\n",
      "Eva_ini_UMF2        1862 non-null float64\n",
      "confianza_n         1862 non-null int64\n",
      "miedo_n             1862 non-null int64\n",
      "Binary_out          1862 non-null float64\n",
      "dtypes: float64(7), int64(2)\n",
      "memory usage: 131.0 KB\n"
     ]
    }
   ],
   "source": [
    "ing = dflist_areas[0].copy() #Select the area\n",
    "ing_red = select_database(5, ing) #Select the database\n",
    "Ttest_selection(ing_red,0.05).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **RFE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling and centering the data\n",
    "from sklearn import preprocessing\n",
    "# Feature ranking with recursive feature elimination and cross-validation\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "def RFE_selection(df,model):\n",
    "    \n",
    "    if len(df.columns) > 2:\n",
    "        predictors = df.columns.to_list()[:-1]\n",
    "        df_sc = preprocessing.scale(df.loc[:,predictors])\n",
    "\n",
    "        X = pd.DataFrame(df_sc, columns = predictors)\n",
    "        y = df['Binary_out']\n",
    "\n",
    "        rfecv = RFECV(estimator=model, step=1, cv=10, scoring='accuracy')\n",
    "        rfecv.fit(X, y)\n",
    "\n",
    "        #print(\"Optimal number of features: %d\" % rfecv.n_features_)\n",
    "        #print('Selected features: %s' % list(X.columns[rfecv.support_]))\n",
    "        sel_vars = list(X.columns[rfecv.support_])\n",
    "        sel_vars.append('Binary_out')\n",
    "        return df[sel_vars]\n",
    "    else:\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Testing it*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1862 entries, 0 to 1861\n",
      "Data columns (total 4 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   CalPromedioPrepa           1862 non-null   float64\n",
      " 1   Puntaje Seccion 14 Examen  1862 non-null   float64\n",
      " 2   Puntaje Seccion 19 Examen  1862 non-null   float64\n",
      " 3   Binary_out                 1862 non-null   float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 58.3 KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "ing = dflist_areas[0].copy() #Select the area\n",
    "ing_red = select_database(0, ing) #Select the database\n",
    "RFE_selection(ing_red,LogisticRegression()).info() \n",
    "#RFE_selection(ing_red,tree.DecisionTreeClassifier()).info() \n",
    "#RFE_selection(ing_red,RandomForestClassifier()).info() \n",
    "#RFE_selection(ing_red,svm.SVC(kernel=\"linear\")).info()\n",
    "\n",
    "#No funcionan****\n",
    "#RFE_selection(ing_red,KNeighborsClassifier()).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Select Feature Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_variables(i,df,corrThres,levelSignificance):\n",
    "    if i == 0:\n",
    "        df_res = PCA_selection(df,corrThres)\n",
    "    elif i == 1:\n",
    "        df_res = Ttest_selection(df,levelSignificance)\n",
    "    elif i == 2:\n",
    "        df_res = df \n",
    "    return df_res\n",
    "\n",
    "def use_rfe(df,model,hymodel, area, database):\n",
    "    df_rfe = RFE_selection(df,model)\n",
    "    predictors = df_rfe.columns.to_list()[:-1]\n",
    "    X = preprocessing.scale(df_rfe.loc[:,predictors])\n",
    "    y = df_rfe['Binary_out']\n",
    "    result = hymodel(X,y,area, database, \"RFE\", predictors)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Testing it*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1862 entries, 0 to 1861\n",
      "Data columns (total 7 columns):\n",
      "CalPromedioPrepa    1862 non-null float64\n",
      "Eva_ini_UMM1        1862 non-null float64\n",
      "Eva_ini_UMM2        1862 non-null float64\n",
      "Eva_ini_UMF1        1862 non-null float64\n",
      "Eva_ini_UMF2        1862 non-null float64\n",
      "Eva_ini_UMC1        1862 non-null float64\n",
      "Binary_out          1862 non-null float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 101.9 KB\n"
     ]
    }
   ],
   "source": [
    "ing = dflist_areas[0].copy() #Select the area\n",
    "ing_red = select_database(1, ing) #Select the database\n",
    "select_variables(2,ing_red,0.37,10).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.69745138 0.48394961 0.23919562]] ['CalPromedioPrepa', 'Puntaje Seccion 14 Examen', 'Puntaje Seccion 19 Examen']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Database</th>\n",
       "      <th>Feature Selection</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Variables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ingenieria</td>\n",
       "      <td>PAA</td>\n",
       "      <td>RFE</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.6974</td>\n",
       "      <td>[CalPromedioPrepa, Puntaje Seccion 14 Examen, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Area Database Feature Selection   Model  Accuracy  \\\n",
       "0  Ingenieria      PAA               RFE  LogReg    0.6974   \n",
       "\n",
       "                                           Variables  \n",
       "0  [CalPromedioPrepa, Puntaje Seccion 14 Examen, ...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ing = dflist_areas[0].copy() #Select the area\n",
    "ing_red = select_database(0, ing) #Select the database\n",
    "\n",
    "use_rfe(ing_red,LogisticRegression(),logit_model, 'Ingenieria', 'PAA')\n",
    "#use_rfe(ing_red,tree.DecisionTreeClassifier(),dt_model, 'Ingenieria', 'PAA')\n",
    "#use_rfe(ing_red,RandomForestClassifier(),rf_model, 'Ingenieria', 'PAA')\n",
    "#use_rfe(ing_red,svm.SVC(kernel=\"linear\"),svm_model, 'Ingenieria', 'PAA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, RepeatedStratifiedKFold, StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "def logit_model(X,y, area, db, fe, predictors):\n",
    "    clf = LogisticRegression(random_state=0)\n",
    "    cv_method = RepeatedStratifiedKFold(n_splits=10,n_repeats=2,random_state=5)\n",
    "    cv_results_full = cross_val_score(estimator=clf, X=X, y=y, cv=cv_method, scoring='accuracy')\n",
    "    accuracy = cv_results_full.mean().round(4)\n",
    "    \n",
    "    #clf_print = LogisticRegression(random_state=0).fit(X, y)#to use only when getting coefficients\n",
    "    #print(clf_print.coef_,predictors)\n",
    "    \n",
    "    return pd.DataFrame(data = {\"Area\": [area], \"Database\":[db], \"Feature Selection\":[fe] ,\n",
    "                                \"Model\":[\"LogReg\"], \"Accuracy\":[accuracy], \"Variables\": [predictors]})\n",
    "\n",
    "def knn_model(X,y, area, db, fe, predictors):\n",
    "    cv_method = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=5)\n",
    "    param_knn = {'n_neighbors': [10,50,100], 'p': [1, 2]}\n",
    "    grs_knn = GridSearchCV(estimator=KNeighborsClassifier(),\n",
    "                      param_grid=param_knn,\n",
    "                      cv=cv_method,\n",
    "                      verbose=False,\n",
    "                      scoring='accuracy')\n",
    "    grs_knn.fit(X, y)\n",
    "    accuracy = grs_knn.best_score_.round(4)\n",
    "    print(grs_knn.best_params_,\" KNN \", accuracy)\n",
    "    return pd.DataFrame(data = {\"Area\": [area], \"Database\":[db], \"Feature Selection\":[fe] , \"Model\":[\"KNN\"],\n",
    "                                \"Accuracy\":[accuracy], \"Variables\": [predictors]})\n",
    "\n",
    "def svm_model(X,y, area, db, fe, predictors):\n",
    "    cv_method = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=5)\n",
    "    param_grid = {'kernel': ['rbf', 'poly', 'linear']} \n",
    "    grs_svc = GridSearchCV(estimator=SVC(),\n",
    "                          param_grid=param_grid,\n",
    "                          cv=cv_method,\n",
    "                          verbose=False,\n",
    "                          scoring='accuracy')\n",
    "    grs_svc.fit(X, y)\n",
    "    accuracy = grs_svc.best_score_.round(4)\n",
    "    print(grs_svc.best_params_,\" SVM \", accuracy)\n",
    "    #svmf_clf = svm.SVC(kernel ='linear')\n",
    "    #svmf_clf.fit(X,y)\n",
    "    #print(svmf_clf.coef_,predictors) #to comment when not getting the coefficents of the models\n",
    "    \n",
    "    return pd.DataFrame(data = {\"Area\": [area], \"Database\":[db], \"Feature Selection\":[fe] , \"Model\":[\"SVM\"],\n",
    "                                \"Accuracy\":[accuracy], \"Variables\": [predictors]})\n",
    "\n",
    "def dt_model(X,y, area, db, fe, predictors):\n",
    "    cv_method = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=5)\n",
    "    param_grid = {'criterion': [ 'gini', 'entropy'], \n",
    "              'max_depth': [2, 5, 10], \n",
    "              'random_state': [17]} \n",
    "    grs_tree = GridSearchCV(estimator=tree.DecisionTreeClassifier(),\n",
    "                      param_grid=param_grid,\n",
    "                      cv=cv_method,\n",
    "                      verbose=False,\n",
    "                      scoring='accuracy')\n",
    "    grs_tree.fit(X, y)\n",
    "    accuracy = grs_tree.best_score_.round(4)\n",
    "    return pd.DataFrame(data = {\"Area\": [area], \"Database\":[db], \"Feature Selection\":[fe] , \"Model\":[\"DT\"],\n",
    "                                \"Accuracy\":[accuracy], \"Variables\": [predictors]})\n",
    "\n",
    "def rf_model(X,y, area, db, fe, predictors):\n",
    "    cv_method = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=5)\n",
    "    param_grid = {'criterion': [ 'gini', 'entropy'], \n",
    "                  'max_depth': [2,5], #2 y 5 \n",
    "                  'random_state': [17],\n",
    "                 'n_estimators': [50,100]} \n",
    "    grs_rf = GridSearchCV(estimator=RandomForestClassifier(),\n",
    "                          param_grid=param_grid,\n",
    "                          cv=cv_method,\n",
    "                          verbose=False,\n",
    "                          scoring='accuracy')\n",
    "    grs_rf.fit(X, y)\n",
    "    accuracy = grs_rf.best_score_.round(4)\n",
    "    print(grs_rf.best_params_,\" RF \", accuracy)\n",
    "    return pd.DataFrame(data = {\"Area\": [area], \"Database\":[db], \"Feature Selection\":[fe] , \"Model\":[\"RF\"],\n",
    "                                \"Accuracy\":[accuracy], \"Variables\": [predictors]})\n",
    "\n",
    "def xgb_model(X,y, area, db, fe, predictors):\n",
    "    cv_method = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=5)\n",
    "    param_grid = {'learning_rate': [0.05,0.01], #0.05 y 0.01\n",
    "                  'max_depth': [8,32], #8 y 32\n",
    "                  'random_state': [17],\n",
    "                  'min_child_weight':[1,6],\n",
    "                 'n_estimators': [100],\n",
    "                 'subsample': [0.5],\n",
    "                 } \n",
    "\n",
    "    grs_xgb = GridSearchCV(estimator= xgb.XGBClassifier(),\n",
    "                          param_grid=param_grid,\n",
    "                          cv=cv_method,\n",
    "                          verbose=False,\n",
    "                          scoring='accuracy')\n",
    "    grs_xgb.fit(X, y)\n",
    "    accuracy = grs_xgb.best_score_.round(4)\n",
    "    print(grs_xgb.best_params_, \"XGB\", accuracy)\n",
    "    return pd.DataFrame(data = {\"Area\": [area], \"Database\":[db], \"Feature Selection\":[fe] , \"Model\":[\"XGB\"],\n",
    "                                \"Accuracy\":[accuracy], \"Variables\": [predictors]})\n",
    "\n",
    "def nb_model(X,y, area, db, fe, predictors):\n",
    "    cv_method = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=5)\n",
    "    param_grid = {'priors': [None] } \n",
    "    grs_nb = GridSearchCV(estimator= GaussianNB(),\n",
    "                          param_grid=param_grid,\n",
    "                          cv=cv_method,\n",
    "                          verbose=False,\n",
    "                          scoring='accuracy')\n",
    "    grs_nb.fit(X, y)\n",
    "    accuracy = grs_nb.best_score_.round(4)\n",
    "    print(grs_nb.best_params_, \" NB \", accuracy)\n",
    "    return pd.DataFrame(data = {\"Area\": [area], \"Database\":[db], \"Feature Selection\":[fe] , \"Model\":[\"NB\"],\n",
    "                                \"Accuracy\":[accuracy], \"Variables\": [predictors]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Testing it*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Database</th>\n",
       "      <th>Feature Selection</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Variables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Engineering</td>\n",
       "      <td>PAA</td>\n",
       "      <td>Ttest</td>\n",
       "      <td>RF</td>\n",
       "      <td>0.7266</td>\n",
       "      <td>[CalPromedioPrepa, Eva_ini_UMM1, Puntaje Secci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Area Database Feature Selection Model  Accuracy  \\\n",
       "0  Engineering      PAA             Ttest    RF    0.7266   \n",
       "\n",
       "                                           Variables  \n",
       "0  [CalPromedioPrepa, Eva_ini_UMM1, Puntaje Secci...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ing = dflist_areas[0].copy() #Select the area\n",
    "ing_red = select_database(14, ing) #Select the database\n",
    "df_test = select_variables(1,ing_red,0.37,0.05)\n",
    "#df_test.info()\n",
    "\n",
    "predictors = df_test.columns.to_list()[:-1]\n",
    "df_sc_t = preprocessing.scale(df_test.loc[:,predictors])\n",
    "\n",
    "X = df_sc_t.copy()\n",
    "y = df_test['Binary_out']\n",
    "\n",
    "#logit_model(X,y, \"Engineering\", \"PAA\", \"Ttest\",predictors)\n",
    "#knn_model(X,y, \"Engineering\", \"PAA\", \"Ttest\",predictors)\n",
    "#svm_model(X,y, \"Engineering\", \"PAA\", \"Ttest\",predictors)\n",
    "#dt_model(X,y, \"Engineering\", \"PAA\", \"Ttest\",predictors)\n",
    "rf_model(X,y, \"Engineering\", \"PAA\", \"Ttest\",predictors)\n",
    "#xgb_model(X,y, \"Engineering\", \"PAA\", \"Ttest\",predictors)\n",
    "#nb_model(X,y, \"Engineering\", \"PAA\", \"Ttest\",predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8. Experiments with hypertunning parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120 entries, 0 to 119\n",
      "Data columns (total 16 columns):\n",
      "CalPromedioPrepa             120 non-null float64\n",
      "Eva_ini_UMM2                 120 non-null float64\n",
      "Eva_ini_UMM3                 120 non-null float64\n",
      "Eva_ini_UMM4                 120 non-null float64\n",
      "Eva_ini_UMF1                 120 non-null float64\n",
      "Eva_ini_UMF2                 120 non-null float64\n",
      "Eva_ini_UMC1                 120 non-null float64\n",
      "Eva_ini_UMC2                 120 non-null float64\n",
      "Puntaje Seccion 8 Examen     120 non-null float64\n",
      "Puntaje Seccion 13 Examen    120 non-null float64\n",
      "Puntaje Seccion 14 Examen    120 non-null float64\n",
      "Puntaje Seccion 19 Examen    120 non-null float64\n",
      "miedo_n                      120 non-null int64\n",
      "sorpresa_n                   120 non-null int64\n",
      "enojo_n                      120 non-null float64\n",
      "Binary_out                   120 non-null float64\n",
      "dtypes: float64(14), int64(2)\n",
      "memory usage: 15.1 KB\n",
      "None\n",
      "{'n_neighbors': 100, 'p': 1}  KNN  0.7417\n",
      "{'priors': None}  NB  0.7542\n",
      "ambienteconstruido Eval + Paa + Senti (120, 16)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120 entries, 0 to 119\n",
      "Data columns (total 22 columns):\n",
      "CalPromedioPrepa             120 non-null float64\n",
      "Eva_ini_UMM2                 120 non-null float64\n",
      "Eva_ini_UMM3                 120 non-null float64\n",
      "Eva_ini_UMM4                 120 non-null float64\n",
      "Eva_ini_UMF1                 120 non-null float64\n",
      "Eva_ini_UMF2                 120 non-null float64\n",
      "Eva_ini_UMC1                 120 non-null float64\n",
      "Eva_ini_UMC2                 120 non-null float64\n",
      "Puntaje Seccion 8 Examen     120 non-null float64\n",
      "Puntaje Seccion 13 Examen    120 non-null float64\n",
      "Puntaje Seccion 14 Examen    120 non-null float64\n",
      "Puntaje Seccion 19 Examen    120 non-null float64\n",
      "P1_ord                       120 non-null float64\n",
      "P2_ord                       120 non-null float64\n",
      "P3_ord                       120 non-null float64\n",
      "P4_ord                       120 non-null float64\n",
      "P5_ord                       120 non-null float64\n",
      "P6_ord                       120 non-null float64\n",
      "P7_ord                       120 non-null float64\n",
      "P8_ord                       120 non-null float64\n",
      "LABORAL_ACTU_ord             120 non-null float64\n",
      "Binary_out                   120 non-null float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 20.7 KB\n",
      "None\n",
      "{'n_neighbors': 100, 'p': 1}  KNN  0.7292\n",
      "{'priors': None}  NB  0.7125\n",
      "ambienteconstruido Eval + Paa + Ord (120, 22)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120 entries, 0 to 119\n",
      "Data columns (total 21 columns):\n",
      "CalPromedioPrepa    120 non-null float64\n",
      "Eva_ini_UMM2        120 non-null float64\n",
      "Eva_ini_UMM3        120 non-null float64\n",
      "Eva_ini_UMM4        120 non-null float64\n",
      "Eva_ini_UMF1        120 non-null float64\n",
      "Eva_ini_UMF2        120 non-null float64\n",
      "Eva_ini_UMC1        120 non-null float64\n",
      "Eva_ini_UMC2        120 non-null float64\n",
      "miedo_n             120 non-null int64\n",
      "sorpresa_n          120 non-null int64\n",
      "enojo_n             120 non-null float64\n",
      "P1_ord              120 non-null float64\n",
      "P2_ord              120 non-null float64\n",
      "P3_ord              120 non-null float64\n",
      "P4_ord              120 non-null float64\n",
      "P5_ord              120 non-null float64\n",
      "P6_ord              120 non-null float64\n",
      "P7_ord              120 non-null float64\n",
      "P8_ord              120 non-null float64\n",
      "LABORAL_ACTU_ord    120 non-null float64\n",
      "Binary_out          120 non-null float64\n",
      "dtypes: float64(19), int64(2)\n",
      "memory usage: 19.8 KB\n",
      "None\n",
      "{'n_neighbors': 100, 'p': 2}  KNN  0.7458\n",
      "{'priors': None}  NB  0.6958\n",
      "ambienteconstruido Eval + Senti + Ord (120, 21)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "df_results = pd.DataFrame(data = {\"Area\": [], \"Database\":[], \"Feature Selection\":[] , \"Model\":[], \"Accuracy\":[], \"Variables\":[]})\n",
    "databases = [\"Paa\",\"Eval\",\"Senti\",\"Ord\",\"Eval + Paa\",\"Eval + Senti\",\"Eval + Ord\",\"Paa + Senti\",\"Paa + Ord\",\n",
    "             \"Senti + Ord\",\"Eval + Paa + Senti\",\"Eval + Paa + Ord\",\"Eval + Senti + Ord\",\"Paa + Senti + Ord\",\"Eval + Paa + Senti + Ord\",'Eval No CalPrepa']\n",
    "fselection = [\"PCA\",\"Ttest\",\"None\"]\n",
    "\n",
    "for i in range(5,6,1): #6 Iteration over all the areas\n",
    "    for j in range(10,13,1): #16 Iteration over all the databases\n",
    "        df_db = select_database(j, dflist_areas[i])\n",
    "        #df_db.insert(3,column = 'Noise', value = np.random.randint(1,1000,df_db.shape[0]))\n",
    "\n",
    "        print(df_db.info())\n",
    "        \n",
    "        for k in range(1,2,1):# 2 Iteration over the feature selection models, avoid PCA only T-test and None\n",
    "            df_fe = select_variables(k,df_db,0.37,0.05) \n",
    "            \n",
    "            if len(df_fe.columns) > 1 :\n",
    "                predictors = df_fe.columns.to_list()[:-1]\n",
    "                df_sc = preprocessing.scale(df_fe.loc[:,predictors])\n",
    "                X = df_sc.copy()\n",
    "                y = df_fe['Binary_out']\n",
    "                \n",
    "                #a = logit_model(X,y,areas[i], databases[j], fselection[k],predictors)\n",
    "                b = knn_model(X,y,  areas[i], databases[j], fselection[k],predictors)\n",
    "                #c = svm_model(X,y,  areas[i], databases[j], fselection[k],predictors)\n",
    "                #d = dt_model(X,y,   areas[i], databases[j], fselection[k],predictors)\n",
    "                #e = rf_model(X,y,   areas[i], databases[j], fselection[k],predictors)\n",
    "                #f = xgb_model(X,y,  areas[i], databases[j], fselection[k],predictors)\n",
    "                g = nb_model(X,y,   areas[i], databases[j], fselection[k],predictors)\n",
    "                \n",
    "            else:# In the case Ttest does not find any variable\n",
    "                a = pd.DataFrame(data = {\"Area\": [areas[i]], \"Database\":[databases[j]], \"Feature Selection\":[fselection[k]] , \"Model\":[\"LogReg\"], \"Accuracy\":[0], \"Variables\":['NONE']})\n",
    "                b = pd.DataFrame(data = {\"Area\": [areas[i]], \"Database\":[databases[j]], \"Feature Selection\":[fselection[k]] , \"Model\":[\"KNN\"], \"Accuracy\":[0], \"Variables\":['NONE']})\n",
    "                c = pd.DataFrame(data = {\"Area\": [areas[i]], \"Database\":[databases[j]], \"Feature Selection\":[fselection[k]] , \"Model\":[\"SVM\"], \"Accuracy\":[0], \"Variables\":['NONE']})\n",
    "                d = pd.DataFrame(data = {\"Area\": [areas[i]], \"Database\":[databases[j]], \"Feature Selection\":[fselection[k]] , \"Model\":[\"DT\"], \"Accuracy\":[0], \"Variables\":['NONE']})\n",
    "                e = pd.DataFrame(data = {\"Area\": [areas[i]], \"Database\":[databases[j]], \"Feature Selection\":[fselection[k]] , \"Model\":[\"RF\"], \"Accuracy\":[0], \"Variables\":['NONE']})\n",
    "                f = pd.DataFrame(data = {\"Area\": [areas[i]], \"Database\":[databases[j]], \"Feature Selection\":[fselection[k]] , \"Model\":[\"XGB\"], \"Accuracy\":[0], \"Variables\":['NONE']})\n",
    "                g = pd.DataFrame(data = {\"Area\": [areas[i]], \"Database\":[databases[j]], \"Feature Selection\":[fselection[k]] , \"Model\":[\"NB\"], \"Accuracy\":[0], \"Variables\":['NONE']})\n",
    "            \n",
    "            #df_results = pd.concat([df_results,a,b,c,d,e], axis = 0)\n",
    "            df_results = pd.concat([df_results,b,g], axis = 0)\n",
    "        \n",
    "        #RFE\n",
    "        #a = use_rfe(df_db,LogisticRegression(),logit_model, areas[i], databases[j])\n",
    "        #b = use_rfe(df_db,svm.SVC(kernel=\"linear\"),svm_model, areas[i], databases[j])\n",
    "        #c = use_rfe(df_db,tree.DecisionTreeClassifier(),dt_model, areas[i], databases[j])\n",
    "        #e = use_rfe(df_db,RandomForestClassifier(),rf_model, areas[i], databases[j])\n",
    "        #f = use_rfe(df_db,xgb.XGBClassifier(),xgb_model, areas[i], databases[j])\n",
    "        \n",
    "        #df_results = pd.concat([df_results,a,b,c,e], axis = 0)\n",
    "        #df_results = pd.concat([df_results,b], axis = 0)\n",
    "        \n",
    "        print(areas[i] , databases[j], df_db.shape)\n",
    "\n",
    "#df_results.head()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv(\"C:/Users/Milara/...\", encoding=\"ISO-8859-1\", index = False) #thus it is necessary to save it as the usual type of coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **9. Noise Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Database</th>\n",
       "      <th>Feature Selection</th>\n",
       "      <th>Model</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Variables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ingenieria</td>\n",
       "      <td>Eval + Paa</td>\n",
       "      <td>None</td>\n",
       "      <td>RF</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'n_estim...</td>\n",
       "      <td>0.73</td>\n",
       "      <td>['CalPromedioPrepa', 'Eva_ini_UMM1', 'Eva_ini_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ingenieria</td>\n",
       "      <td>Eval + Paa</td>\n",
       "      <td>RFE</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.73</td>\n",
       "      <td>['CalPromedioPrepa', 'Eva_ini_UMM1', 'Eva_ini_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negocios</td>\n",
       "      <td>Paa + Senti + Ord</td>\n",
       "      <td>RFE</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.70</td>\n",
       "      <td>['CalPromedioPrepa', 'Puntaje Seccion 8 Examen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negocios</td>\n",
       "      <td>Eval + Paa + Senti + Ord</td>\n",
       "      <td>RFE</td>\n",
       "      <td>SVM</td>\n",
       "      <td>{'kernel': 'linear'}</td>\n",
       "      <td>0.70</td>\n",
       "      <td>['P6_ord', 'LABORAL_ACTU_ord', 'confianza_n', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>estudioscreativos</td>\n",
       "      <td>Senti</td>\n",
       "      <td>Ttest</td>\n",
       "      <td>NB</td>\n",
       "      <td>{'priors': None}</td>\n",
       "      <td>0.63</td>\n",
       "      <td>['CalPromedioPrepa', 'confianza_n']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Area                  Database Feature Selection   Model  \\\n",
       "0         ingenieria                Eval + Paa              None      RF   \n",
       "1         ingenieria                Eval + Paa               RFE  LogReg   \n",
       "2           negocios         Paa + Senti + Ord               RFE  LogReg   \n",
       "3           negocios  Eval + Paa + Senti + Ord               RFE     SVM   \n",
       "4  estudioscreativos                     Senti             Ttest      NB   \n",
       "\n",
       "                                          Parameters  Accuracy  \\\n",
       "0  {'criterion': 'gini', 'max_depth': 5, 'n_estim...      0.73   \n",
       "1                                                NOT      0.73   \n",
       "2                                                NOT      0.70   \n",
       "3                               {'kernel': 'linear'}      0.70   \n",
       "4                                   {'priors': None}      0.63   \n",
       "\n",
       "                                           Variables  \n",
       "0  ['CalPromedioPrepa', 'Eva_ini_UMM1', 'Eva_ini_...  \n",
       "1  ['CalPromedioPrepa', 'Eva_ini_UMM1', 'Eva_ini_...  \n",
       "2  ['CalPromedioPrepa', 'Puntaje Seccion 8 Examen...  \n",
       "3  ['P6_ord', 'LABORAL_ACTU_ord', 'confianza_n', ...  \n",
       "4                ['CalPromedioPrepa', 'confianza_n']  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the file with the data of the best experiments\n",
    "df_exp = pd.read_csv(\"C:/Users/Milara/...\",encoding=\"ISO-8859-1\")\n",
    "df_exp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to help reading the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the string of variables into a list\n",
    "def string_2list(string):\n",
    "    a = string\n",
    "    char_remove = ['[',']','\\'']\n",
    "    for elem in char_remove:\n",
    "        a = a.replace(elem, '')\n",
    "    return a.split(sep = ', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, RepeatedStratifiedKFold, StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "import xgboost as xgb\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import ast\n",
    "import shap\n",
    "\n",
    "scoring_metric = 'accuracy' # used to get the precision and recall from the models\n",
    "\n",
    "def logreg_model_S(X,y, area, parameters, predictors, coefficients = False):\n",
    "    clf = LogisticRegression(random_state=0)\n",
    "    cv_method = RepeatedStratifiedKFold(n_splits=10,n_repeats=2,random_state=5)\n",
    "    cv_results_full = cross_val_score(estimator=clf, X=X, y=y, cv=cv_method, scoring= scoring_metric)\n",
    "    accuracy = cv_results_full.mean().round(4)\n",
    "    \n",
    "    coefficients_clf = []\n",
    "    if coefficients:\n",
    "        clf_print = LogisticRegression(random_state=0).fit(X, y)#to use only when getting coefficients\n",
    "        coefficients_clf = clf_print.coef_\n",
    "\n",
    "    return pd.DataFrame(data = {\"Area\": [area],\"Model\":[\"LogReg\"], \"Parameters\": [parameters], \"Accuracy\":[accuracy], \"CV Results\": [cv_results_full],\n",
    "                       \"Variables\" : [predictors], \"Coefficients\" : [coefficients_clf]})\n",
    "\n",
    "def knn_model_S(X,y, area, parameters, predictors):\n",
    "    cv_method = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=5)\n",
    "    param_grid = parameters\n",
    "    grs_knn = GridSearchCV(estimator=KNeighborsClassifier(),\n",
    "                      param_grid=param_grid,\n",
    "                      cv=cv_method,\n",
    "                      verbose=False,\n",
    "                      scoring= scoring_metric)\n",
    "    grs_knn.fit(X, y)\n",
    "    accuracy = grs_knn.best_score_.round(4)\n",
    "    #print(grs_knn.best_params_,\" KNN \", accuracy)\n",
    "    \n",
    "    knn_cv = pd.DataFrame(grs_knn.cv_results_)\n",
    "    filteredList = list(filter(lambda x: x[0:5] == 'split', knn_cv.columns))\n",
    "    \n",
    "    return pd.DataFrame(data = {\"Area\": [area],\"Model\":[\"KNN\"], \"Parameters\": [parameters], \"Accuracy\":[accuracy], \"CV Results\": [knn_cv[filteredList].stack().values],\n",
    "                       \"Variables\" : [predictors], \"Coefficients\" : ['NOT']})\n",
    "\n",
    "\n",
    "def svm_model_S(X,y, area, parameters, predictors, coefficients = False):\n",
    "    cv_method = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=5)\n",
    "    param_grid = parameters\n",
    "    grs_svc = GridSearchCV(estimator=SVC(),\n",
    "                          param_grid=param_grid,\n",
    "                          cv=cv_method,\n",
    "                          verbose=False,\n",
    "                          scoring=scoring_metric)\n",
    "    grs_svc.fit(X, y)\n",
    "    accuracy = grs_svc.best_score_.round(4)\n",
    "    #print(grs_svc.best_params_,\" SVM \", accuracy)\n",
    "    \n",
    "    coefficients_svc = []\n",
    "    if coefficients:\n",
    "        svc_print = svm.SVC(kernel ='linear').fit(X, y)#to use only when getting coefficients\n",
    "        coefficients_svc = svc_print.coef_\n",
    "    \n",
    "    svc_cv = pd.DataFrame(grs_svc.cv_results_)\n",
    "    filteredList = list(filter(lambda x: x[0:5] == 'split', svc_cv.columns))\n",
    "    \n",
    "    return pd.DataFrame(data = {\"Area\": [area],\"Model\":[\"SVM\"], \"Parameters\": [parameters], \"Accuracy\":[accuracy], \"CV Results\": [svc_cv[filteredList].stack().values],\n",
    "                       \"Variables\" : [predictors], \"Coefficients\" : [coefficients_svc]})\n",
    "\n",
    "def dt_model_S(X,y, area, parameters, predictors):\n",
    "    cv_method = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=5)\n",
    "    param_grid = parameters\n",
    "    grs_tree = GridSearchCV(estimator=tree.DecisionTreeClassifier(),\n",
    "                      param_grid=param_grid,\n",
    "                      cv=cv_method,\n",
    "                      verbose=False,\n",
    "                      scoring=scoring_metric)\n",
    "    grs_tree.fit(X, y)\n",
    "    accuracy = grs_tree.best_score_.round(4)\n",
    "    \n",
    "    return pd.DataFrame(data = {\"Area\": [area],\"Model\":[\"DT\"], \"Parameters\": [parameters], \"Accuracy\":[accuracy],\n",
    "                                \"Variables\": [predictors],\"Coefficients\" : ['NOT']})\n",
    "\n",
    "def rf_model_S(X,y, area, parameters, predictors):\n",
    "    cv_method = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=5)\n",
    "    param_grid = parameters \n",
    "    grs_rf = GridSearchCV(estimator=RandomForestClassifier(),\n",
    "                          param_grid=param_grid,\n",
    "                          cv=cv_method,\n",
    "                          verbose=False,\n",
    "                          scoring=scoring_metric)\n",
    "    grs_rf.fit(X, y)\n",
    "    accuracy = grs_rf.best_score_.round(4)\n",
    "    #print(grs_rf.best_params_,\" RF \", accuracy)\n",
    "    \n",
    "    rf_cv = pd.DataFrame(grs_rf.cv_results_)\n",
    "    filteredList = list(filter(lambda x: x[0:5] == 'split', rf_cv.columns))\n",
    "    \n",
    "    return pd.DataFrame(data = {\"Area\": [area],\"Model\":[\"RF\"], \"Parameters\": [parameters], \"Accuracy\":[accuracy], \"CV Results\": [rf_cv[filteredList].stack().values],\n",
    "                       \"Variables\" : [predictors],\"Coefficients\" : ['NOT']})\n",
    "\n",
    "def xgb_model_S(X,y, area, parameters, predictors, coefficients = False):\n",
    "    cv_method = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=5)\n",
    "    param_grid = parameters \n",
    "\n",
    "    grs_xgb = GridSearchCV(estimator= xgb.XGBClassifier(use_label_encoder = False),\n",
    "                          param_grid=param_grid,\n",
    "                          cv=cv_method,\n",
    "                          verbose=False,\n",
    "                          scoring=scoring_metric)\n",
    "    grs_xgb.fit(X, y)\n",
    "    accuracy = grs_xgb.best_score_.round(4)\n",
    "    #print(grs_xgb.best_params_, \"XGB\", accuracy)\n",
    "    \n",
    "    \n",
    "    coefficients_xgb = []\n",
    "    #if coefficients:\n",
    "     #   xgb_print = xgb.XGBClassifier(b).fit(X, y)#to use only when getting coefficients NOT WORKING WITH PARAMETERS AS DICT\n",
    "        #coefficients_xgb = xgb_print.feature_importances_\n",
    "    \n",
    "    xgb_cv = pd.DataFrame(grs_xgb.cv_results_)\n",
    "    filteredList = list(filter(lambda x: x[0:5] == 'split', xgb_cv.columns))\n",
    "    \n",
    "    return pd.DataFrame(data = {\"Area\": [area],\"Model\":[\"XGB\"], \"Parameters\": [parameters], \"Accuracy\":[accuracy], \"CV Results\": [xgb_cv[filteredList].stack().values],\n",
    "                       \"Variables\" : [predictors], \"Coefficients\" : [coefficients_xgb]})\n",
    "\n",
    "def nb_model_S(X,y, area, parameters, predictors):\n",
    "    cv_method = RepeatedStratifiedKFold(n_splits=10, n_repeats=2, random_state=5)\n",
    "    param_grid = parameters\n",
    "    grs_nb = GridSearchCV(estimator= GaussianNB(),\n",
    "                          param_grid=param_grid,\n",
    "                          cv=cv_method,\n",
    "                          verbose=False,\n",
    "                          scoring=scoring_metric)\n",
    "    grs_nb.fit(X, y)\n",
    "    accuracy = grs_nb.best_score_.round(4)\n",
    "    #print(grs_nb.best_params_, \" NB \", accuracy)\n",
    "\n",
    "    nb_cv = pd.DataFrame(grs_nb.cv_results_)\n",
    "    filteredList = list(filter(lambda x: x[0:5] == 'split', nb_cv.columns))\n",
    "    \n",
    "    return pd.DataFrame(data = {\"Area\": [area],\"Model\":[\"NB\"], \"Parameters\": [parameters], \"Accuracy\":[accuracy], \"CV Results\": [nb_cv[filteredList].stack().values],\n",
    "                       \"Variables\" : [predictors],\"Coefficients\" : ['NOT']})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to run the comparision between experiments with and without noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import random\n",
    "\n",
    "def run_cv(df_inuse,id_area,noise_flag = False):\n",
    "    \"\"\"\n",
    "    Function to run the experiments based on their parameters and noise and return the cv results\n",
    "    Input: \n",
    "        df with the experiments to be run,\n",
    "        value of id of the area\n",
    "        boolean value for the flag\n",
    "    Output:\n",
    "        df with the cross validation scores\n",
    "    \"\"\"\n",
    "    df_inuse = df_inuse[df_inuse['Database'] != 'Eval No CalPrepa'].drop(['Feature Selection', 'Accuracy','Database'], axis = 1) #remove experiment not needed\n",
    "    df_db = dflist_areas[id_area]# Get the full database\n",
    "\n",
    "    #Store the data to configure the experiment\n",
    "    models = df_inuse['Model'].tolist()\n",
    "    variables = df_inuse['Variables'].tolist()\n",
    "    parameters = df_inuse['Parameters'].tolist()\n",
    "    \n",
    "    list_results = list()\n",
    "\n",
    "    #Compute the models\n",
    "    for i in range(len(models)):\n",
    "        list_variables = string_2list(variables[i]) # get the list of variables to be used in the model\n",
    "\n",
    "        #get the parameters for the model\n",
    "        if parameters[i] != 'NOT':\n",
    "            dict_param = ast.literal_eval(parameters[i])\n",
    "\n",
    "            for elem in dict_param.keys(): #transform to list the values of each key\n",
    "                dict_param[elem] = [dict_param[elem]]\n",
    "        else:\n",
    "            dict_param = 'NA'\n",
    "\n",
    "        #Clean the db with the selected variables\n",
    "        data_samples = df_db.loc[:,list_variables]\n",
    "        \n",
    "        if noise_flag:#used only if flag enabled\n",
    "            #np.random.seed(100)\n",
    "            data_samples.insert(0,column = 'Noise', value = np.random.randint(1,1000,df_db.shape[0])) # Noise added\n",
    "            \n",
    "        X = preprocessing.scale(data_samples)\n",
    "        y = df_db['Binary_out']\n",
    "        model = models[i].lower() \n",
    "\n",
    "        #Compute the model\n",
    "        if model == 'rf':\n",
    "            rf_res = rf_model_S(X,y, areas[id_area], dict_param, data_samples.columns.tolist())\n",
    "            list_results.append(rf_res)\n",
    "        elif model == 'logreg':\n",
    "            log_res = logreg_model_S(X,y, areas[id_area], dict_param, data_samples.columns.tolist())\n",
    "            list_results.append(log_res)\n",
    "        elif model == 'svm':\n",
    "            svm_res = svm_model_S(X,y, areas[id_area], dict_param, data_samples.columns.tolist())\n",
    "            list_results.append(svm_res)\n",
    "        elif model == 'knn':\n",
    "            knn_res = knn_model_S(X,y, areas[id_area], dict_param, data_samples.columns.tolist())\n",
    "            list_results.append(knn_res)\n",
    "        elif model == 'nb':\n",
    "            nb_res = nb_model_S(X,y, areas[id_area], dict_param, data_samples.columns.tolist())\n",
    "            list_results.append(nb_res)\n",
    "        elif model == 'xgb':\n",
    "            xgb_res = xgb_model_S(X,y, areas[id_area], dict_param, data_samples.columns.tolist())\n",
    "            list_results.append(xgb_res)\n",
    "\n",
    "    return pd.concat(list_results, axis = 0)\n",
    "\n",
    "\n",
    "def paired_ttest(base_cv,noise_cv):\n",
    "    \"\"\"\n",
    "    Function that is used to compare the mean using paired t test\n",
    "    Input: two df \n",
    "    Output: model with less difference in the means\n",
    "    \"\"\"\n",
    "    model_winner = \"\"\n",
    "    pvalue_winner = 0\n",
    "    variables_winner = list()\n",
    "    accuracy_winner = 0\n",
    "    parameters_winner = dict()\n",
    "\n",
    "    for i in range(len(base_cv.index)):\n",
    "        statistic, pvalue = stats.ttest_rel(base_cv['CV Results'][i], noise_cv['CV Results'][i])\n",
    "        if pvalue_winner < pvalue:\n",
    "            pvalue_winner  = pvalue\n",
    "            model_winner = base_cv['Model'][i]\n",
    "            variables_winner = base_cv['Variables'][i]\n",
    "            accuracy_winner = base_cv['Accuracy'][i]\n",
    "            parameters_winner = base_cv['Parameters'][i]\n",
    "\n",
    "    return(base_cv['Area'][i],variables_winner,model_winner,pvalue_winner,accuracy_winner,parameters_winner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Testing it*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "areas = ['ingenieria', 'negocios','estudioscreativos', 'salud', 'cienciassociales', 'ambienteconstruido']\n",
    "id_area = 0\n",
    "winner_list = []\n",
    "repeat_list = []\n",
    "\n",
    "for i in range(3):\n",
    "    for i in range(len(areas)):\n",
    "        #Get the data for the experiment\n",
    "        df_inuse = df_exp[df_exp['Area'] == areas[i]] # Select the area\n",
    "        #compute the cross validation results\n",
    "        base_cv = run_cv(df_inuse,i).reset_index().drop('index', axis = 1)\n",
    "        noise_cv = run_cv(df_inuse,i,True).reset_index().drop('index', axis = 1)\n",
    "        #compare the cross validation results with paired t test\n",
    "        warea, wvariables, wmodel, wpvalue, waccuracy, wparameters = paired_ttest(base_cv,noise_cv)\n",
    "        winner = pd.DataFrame(data = {\"Area\": [warea],\"Model\":[wmodel], \"Parameters\": [wparameters], \"Accuracy\":[waccuracy], \"Variables\" : [wvariables]})\n",
    "        winner_list.append(winner)\n",
    "\n",
    "    winner_df = pd.concat(winner_list, axis = 0)\n",
    "    repeat_list.append(winner_df)\n",
    "    \n",
    "#winner_df.to_csv(\"C:/Users/Milara/..., encoding=\"ISO-8859-1\", index = False) #thus it is necessary to save it as the usual type of coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Model</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Variables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ingenieria</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.7256</td>\n",
       "      <td>[CalPromedioPrepa, Eva_ini_UMM1, Eva_ini_UMM2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negocios</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.7034</td>\n",
       "      <td>[CalPromedioPrepa, Puntaje Seccion 8 Examen, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>estudioscreativos</td>\n",
       "      <td>SVM</td>\n",
       "      <td>{'kernel': ['linear']}</td>\n",
       "      <td>0.6295</td>\n",
       "      <td>[CalPromedioPrepa, Eva_ini_UMM1, Eva_ini_UMM2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>salud</td>\n",
       "      <td>XGB</td>\n",
       "      <td>{'learning_rate': [0.05], 'max_depth': [8], 'm...</td>\n",
       "      <td>0.6648</td>\n",
       "      <td>[CalPromedioPrepa, enojo_n]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cienciassociales</td>\n",
       "      <td>NB</td>\n",
       "      <td>{'priors': [None]}</td>\n",
       "      <td>0.7199</td>\n",
       "      <td>[CalPromedioPrepa, Puntaje Seccion 21 Examen, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ambienteconstruido</td>\n",
       "      <td>NB</td>\n",
       "      <td>{'priors': [None]}</td>\n",
       "      <td>0.7542</td>\n",
       "      <td>[CalPromedioPrepa, Eva_ini_UMF1, Eva_ini_UMM2,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Area   Model  \\\n",
       "0          ingenieria  LogReg   \n",
       "0            negocios  LogReg   \n",
       "0   estudioscreativos     SVM   \n",
       "0               salud     XGB   \n",
       "0    cienciassociales      NB   \n",
       "0  ambienteconstruido      NB   \n",
       "\n",
       "                                          Parameters  Accuracy  \\\n",
       "0                                                 NA    0.7256   \n",
       "0                                                 NA    0.7034   \n",
       "0                             {'kernel': ['linear']}    0.6295   \n",
       "0  {'learning_rate': [0.05], 'max_depth': [8], 'm...    0.6648   \n",
       "0                                 {'priors': [None]}    0.7199   \n",
       "0                                 {'priors': [None]}    0.7542   \n",
       "\n",
       "                                           Variables  \n",
       "0  [CalPromedioPrepa, Eva_ini_UMM1, Eva_ini_UMM2,...  \n",
       "0  [CalPromedioPrepa, Puntaje Seccion 8 Examen, P...  \n",
       "0  [CalPromedioPrepa, Eva_ini_UMM1, Eva_ini_UMM2,...  \n",
       "0                        [CalPromedioPrepa, enojo_n]  \n",
       "0  [CalPromedioPrepa, Puntaje Seccion 21 Examen, ...  \n",
       "0  [CalPromedioPrepa, Eva_ini_UMF1, Eva_ini_UMM2,...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat_list[0].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Model</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Variables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ingenieria</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.7256</td>\n",
       "      <td>[CalPromedioPrepa, Eva_ini_UMM1, Eva_ini_UMM2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negocios</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.7034</td>\n",
       "      <td>[CalPromedioPrepa, Puntaje Seccion 8 Examen, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>estudioscreativos</td>\n",
       "      <td>SVM</td>\n",
       "      <td>{'kernel': ['linear']}</td>\n",
       "      <td>0.6295</td>\n",
       "      <td>[CalPromedioPrepa, Eva_ini_UMM1, Eva_ini_UMM2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>salud</td>\n",
       "      <td>XGB</td>\n",
       "      <td>{'learning_rate': [0.05], 'max_depth': [8], 'm...</td>\n",
       "      <td>0.6648</td>\n",
       "      <td>[CalPromedioPrepa, enojo_n]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cienciassociales</td>\n",
       "      <td>NB</td>\n",
       "      <td>{'priors': [None]}</td>\n",
       "      <td>0.7199</td>\n",
       "      <td>[CalPromedioPrepa, Puntaje Seccion 21 Examen, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ambienteconstruido</td>\n",
       "      <td>NB</td>\n",
       "      <td>{'priors': [None]}</td>\n",
       "      <td>0.7542</td>\n",
       "      <td>[CalPromedioPrepa, Eva_ini_UMF1, Eva_ini_UMM2,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Area   Model  \\\n",
       "0          ingenieria  LogReg   \n",
       "0            negocios  LogReg   \n",
       "0   estudioscreativos     SVM   \n",
       "0               salud     XGB   \n",
       "0    cienciassociales      NB   \n",
       "0  ambienteconstruido      NB   \n",
       "\n",
       "                                          Parameters  Accuracy  \\\n",
       "0                                                 NA    0.7256   \n",
       "0                                                 NA    0.7034   \n",
       "0                             {'kernel': ['linear']}    0.6295   \n",
       "0  {'learning_rate': [0.05], 'max_depth': [8], 'm...    0.6648   \n",
       "0                                 {'priors': [None]}    0.7199   \n",
       "0                                 {'priors': [None]}    0.7542   \n",
       "\n",
       "                                           Variables  \n",
       "0  [CalPromedioPrepa, Eva_ini_UMM1, Eva_ini_UMM2,...  \n",
       "0  [CalPromedioPrepa, Puntaje Seccion 8 Examen, P...  \n",
       "0  [CalPromedioPrepa, Eva_ini_UMM1, Eva_ini_UMM2,...  \n",
       "0                        [CalPromedioPrepa, enojo_n]  \n",
       "0  [CalPromedioPrepa, Puntaje Seccion 21 Examen, ...  \n",
       "0  [CalPromedioPrepa, Eva_ini_UMF1, Eva_ini_UMM2,...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat_list[1].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Model</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Variables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ingenieria</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.7256</td>\n",
       "      <td>[CalPromedioPrepa, Eva_ini_UMM1, Eva_ini_UMM2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negocios</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.7034</td>\n",
       "      <td>[CalPromedioPrepa, Puntaje Seccion 8 Examen, P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>estudioscreativos</td>\n",
       "      <td>SVM</td>\n",
       "      <td>{'kernel': ['linear']}</td>\n",
       "      <td>0.6295</td>\n",
       "      <td>[CalPromedioPrepa, Eva_ini_UMM1, Eva_ini_UMM2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>salud</td>\n",
       "      <td>XGB</td>\n",
       "      <td>{'learning_rate': [0.05], 'max_depth': [8], 'm...</td>\n",
       "      <td>0.6648</td>\n",
       "      <td>[CalPromedioPrepa, enojo_n]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cienciassociales</td>\n",
       "      <td>NB</td>\n",
       "      <td>{'priors': [None]}</td>\n",
       "      <td>0.7199</td>\n",
       "      <td>[CalPromedioPrepa, Puntaje Seccion 21 Examen, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ambienteconstruido</td>\n",
       "      <td>NB</td>\n",
       "      <td>{'priors': [None]}</td>\n",
       "      <td>0.7542</td>\n",
       "      <td>[CalPromedioPrepa, Eva_ini_UMF1, Eva_ini_UMM2,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Area   Model  \\\n",
       "0          ingenieria  LogReg   \n",
       "0            negocios  LogReg   \n",
       "0   estudioscreativos     SVM   \n",
       "0               salud     XGB   \n",
       "0    cienciassociales      NB   \n",
       "0  ambienteconstruido      NB   \n",
       "\n",
       "                                          Parameters  Accuracy  \\\n",
       "0                                                 NA    0.7256   \n",
       "0                                                 NA    0.7034   \n",
       "0                             {'kernel': ['linear']}    0.6295   \n",
       "0  {'learning_rate': [0.05], 'max_depth': [8], 'm...    0.6648   \n",
       "0                                 {'priors': [None]}    0.7199   \n",
       "0                                 {'priors': [None]}    0.7542   \n",
       "\n",
       "                                           Variables  \n",
       "0  [CalPromedioPrepa, Eva_ini_UMM1, Eva_ini_UMM2,...  \n",
       "0  [CalPromedioPrepa, Puntaje Seccion 8 Examen, P...  \n",
       "0  [CalPromedioPrepa, Eva_ini_UMM1, Eva_ini_UMM2,...  \n",
       "0                        [CalPromedioPrepa, enojo_n]  \n",
       "0  [CalPromedioPrepa, Puntaje Seccion 21 Examen, ...  \n",
       "0  [CalPromedioPrepa, Eva_ini_UMF1, Eva_ini_UMM2,...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repeat_list[2].head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat_list[0].to_csv(\"C:/Users/Milara/...\", encoding=\"ISO-8859-1\", index = False) #thus it is necessary to save it as the usual type of coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **10: Comparing the EVAL NO CAL PREPA VS THE BEST EXPERIMENTS with an statistical test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Model</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Variables</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ingenieria</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.7256</td>\n",
       "      <td>['CalPromedioPrepa', 'Eva_ini_UMM1', 'Eva_ini_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negocios</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.7034</td>\n",
       "      <td>['CalPromedioPrepa', 'Puntaje Seccion 8 Examen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>estudioscreativos</td>\n",
       "      <td>SVM</td>\n",
       "      <td>{'kernel': 'linear'}</td>\n",
       "      <td>0.6295</td>\n",
       "      <td>['CalPromedioPrepa', 'Eva_ini_UMM1', 'Eva_ini_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>salud</td>\n",
       "      <td>XGB</td>\n",
       "      <td>{'learning_rate': 0.05, 'max_depth': 8, 'min_c...</td>\n",
       "      <td>0.6648</td>\n",
       "      <td>['CalPromedioPrepa', 'enojo_n']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cienciassociales</td>\n",
       "      <td>NB</td>\n",
       "      <td>{'priors': None}</td>\n",
       "      <td>0.7199</td>\n",
       "      <td>['CalPromedioPrepa', 'Puntaje Seccion 21 Exame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ambienteconstruido</td>\n",
       "      <td>NB</td>\n",
       "      <td>{'priors': None}</td>\n",
       "      <td>0.7542</td>\n",
       "      <td>['CalPromedioPrepa', 'Eva_ini_UMF1', 'Eva_ini_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ingenieria</td>\n",
       "      <td>SVM</td>\n",
       "      <td>{'kernel': 'rbf'}</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>['Eva_ini_UMM1', 'Eva_ini_UMM2', 'Eva_ini_UMF1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>negocios</td>\n",
       "      <td>SVM</td>\n",
       "      <td>{'kernel': 'linear'}</td>\n",
       "      <td>0.6100</td>\n",
       "      <td>['Eva_ini_UMM1', 'Eva_ini_UMM2', 'Eva_ini_UMM3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>estudioscreativos</td>\n",
       "      <td>XGB</td>\n",
       "      <td>{'learning_rate': 0.01, 'max_depth': 8, 'min_c...</td>\n",
       "      <td>0.6200</td>\n",
       "      <td>['Eva_ini_UMM2', 'Eva_ini_UMF1', 'Eva_ini_UMC1']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>salud</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>NOT</td>\n",
       "      <td>0.6100</td>\n",
       "      <td>['Eva_ini_UMQ2']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Area   Model  \\\n",
       "0          ingenieria  LogReg   \n",
       "1            negocios  LogReg   \n",
       "2   estudioscreativos     SVM   \n",
       "3               salud     XGB   \n",
       "4    cienciassociales      NB   \n",
       "5  ambienteconstruido      NB   \n",
       "6          ingenieria     SVM   \n",
       "7            negocios     SVM   \n",
       "8   estudioscreativos     XGB   \n",
       "9               salud  LogReg   \n",
       "\n",
       "                                          Parameters  Accuracy  \\\n",
       "0                                                NOT    0.7256   \n",
       "1                                                NOT    0.7034   \n",
       "2                               {'kernel': 'linear'}    0.6295   \n",
       "3  {'learning_rate': 0.05, 'max_depth': 8, 'min_c...    0.6648   \n",
       "4                                   {'priors': None}    0.7199   \n",
       "5                                   {'priors': None}    0.7542   \n",
       "6                                  {'kernel': 'rbf'}    0.6800   \n",
       "7                               {'kernel': 'linear'}    0.6100   \n",
       "8  {'learning_rate': 0.01, 'max_depth': 8, 'min_c...    0.6200   \n",
       "9                                                NOT    0.6100   \n",
       "\n",
       "                                           Variables  \n",
       "0  ['CalPromedioPrepa', 'Eva_ini_UMM1', 'Eva_ini_...  \n",
       "1  ['CalPromedioPrepa', 'Puntaje Seccion 8 Examen...  \n",
       "2  ['CalPromedioPrepa', 'Eva_ini_UMM1', 'Eva_ini_...  \n",
       "3                    ['CalPromedioPrepa', 'enojo_n']  \n",
       "4  ['CalPromedioPrepa', 'Puntaje Seccion 21 Exame...  \n",
       "5  ['CalPromedioPrepa', 'Eva_ini_UMF1', 'Eva_ini_...  \n",
       "6  ['Eva_ini_UMM1', 'Eva_ini_UMM2', 'Eva_ini_UMF1...  \n",
       "7  ['Eva_ini_UMM1', 'Eva_ini_UMM2', 'Eva_ini_UMM3...  \n",
       "8   ['Eva_ini_UMM2', 'Eva_ini_UMF1', 'Eva_ini_UMC1']  \n",
       "9                                   ['Eva_ini_UMQ2']  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Read the file with the data of the best experiments\n",
    "df_dif = pd.read_csv(\"C:/Users/Milara/...\",encoding=\"ISO-8859-1\")\n",
    "df_dif.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to compare both types of experiments (based on previous code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import random\n",
    "\n",
    "def run_cv_2(df_inuse,id_area,noise_flag = False, coef_flag = False):\n",
    "    \"\"\"\n",
    "    Function to run the experiments based on their parameters and noise and return the cv results\n",
    "    Input: \n",
    "        df with the experiments to be run,\n",
    "        value of id of the area\n",
    "        boolean value for the flag\n",
    "    Output:\n",
    "        df with the cross validation scores\n",
    "    \"\"\"\n",
    "    df_db = dflist_areas[id_area]# Get the full database\n",
    "    \n",
    "\n",
    "    #Store the data to configure the experiment\n",
    "    models = df_inuse['Model'].tolist()\n",
    "    variables = df_inuse['Variables'].tolist()\n",
    "    parameters = df_inuse['Parameters'].tolist()\n",
    "    \n",
    "    list_results = list()\n",
    "\n",
    "    #Compute the models\n",
    "    for i in range(len(models)):\n",
    "        list_variables = string_2list(variables[i]) # get the list of variables to be used in the model\n",
    "        \n",
    "        #get the parameters for the model\n",
    "        if parameters[i] != 'NOT':\n",
    "            dict_param = ast.literal_eval(parameters[i])\n",
    "\n",
    "            for elem in dict_param.keys(): #transform to list the values of each key\n",
    "                dict_param[elem] = [dict_param[elem]]\n",
    "        else:\n",
    "            dict_param = 'NA'\n",
    "\n",
    "        #Clean the db with the selected variables\n",
    "        data_samples = df_db.loc[:,list_variables]\n",
    "        \n",
    "        if noise_flag:#used only if flag enabled\n",
    "            #np.random.seed(100)\n",
    "            data_samples.insert(0,column = 'Noise', value = np.random.randint(1,1000,df_db.shape[0])) # Noise added\n",
    "            \n",
    "        X = preprocessing.scale(data_samples)\n",
    "        y = df_db['Binary_out']\n",
    "        model = models[i].lower() \n",
    "\n",
    "        #Compute the model\n",
    "        if model == 'rf':\n",
    "            rf_res = rf_model_S(X,y, areas[id_area], dict_param, data_samples.columns.tolist())\n",
    "            list_results.append(rf_res)\n",
    "        elif model == 'logreg':\n",
    "            log_res = logreg_model_S(X,y, areas[id_area], dict_param, data_samples.columns.tolist(), coefficients = coef_flag)\n",
    "            list_results.append(log_res)\n",
    "        elif model == 'svm':\n",
    "            svm_res = svm_model_S(X,y, areas[id_area], dict_param, data_samples.columns.tolist(), coefficients = coef_flag)\n",
    "            list_results.append(svm_res)\n",
    "        elif model == 'knn':\n",
    "            knn_res = knn_model_S(X,y, areas[id_area], dict_param, data_samples.columns.tolist())\n",
    "            list_results.append(knn_res)\n",
    "        elif model == 'nb':\n",
    "            nb_res = nb_model_S(X,y, areas[id_area], dict_param, data_samples.columns.tolist())\n",
    "            list_results.append(nb_res)\n",
    "        elif model == 'xgb':\n",
    "            xgb_res = xgb_model_S(X,y, areas[id_area], dict_param, data_samples.columns.tolist(), coefficients = coef_flag)\n",
    "            list_results.append(xgb_res)\n",
    "\n",
    "    return pd.concat(list_results, axis = 0)\n",
    "\n",
    "\n",
    "def paired_ttest_2(base_cv,noise_cv):\n",
    "    \"\"\"\n",
    "    Function that is used to compare the mean using paired t test\n",
    "    Input: two df \n",
    "    Output: model with less difference in the means\n",
    "    \"\"\"\n",
    "    statistic, pvalue = stats.ttest_rel(base_cv['CV Results'][0], noise_cv['CV Results'][0])\n",
    "    return(pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Testing it*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ingenieria AD metric: [0.7301]\n",
      "ingenieria EvalOnly metric: [0.7131]\n",
      "negocios AD metric: [0.7185]\n",
      "negocios EvalOnly metric: [0.6297]\n",
      "[13:24:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:29] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:30] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "estudioscreativos AD metric: [0.6466]\n",
      "estudioscreativos EvalOnly metric: [0.6217]\n",
      "[13:24:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:31] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[13:24:32] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "salud AD metric: [0.6715]\n",
      "salud EvalOnly metric: [0.6038]\n",
      "cienciassociales AD metric: [0.7252]\n",
      "cienciassociales EvalOnly metric: [0.6125]\n",
      "ambienteconstruido AD metric: [0.7873]\n",
      "ambienteconstruido EvalOnly metric: [0.7568]\n"
     ]
    }
   ],
   "source": [
    "areas = ['ingenieria', 'negocios','estudioscreativos', 'salud', 'cienciassociales', 'ambienteconstruido']\n",
    "id_area = 0\n",
    "winner_list = []\n",
    "\n",
    "for i in range(6): #\n",
    "    #Get the data for the experiment\n",
    "    df_inuse = df_dif[df_dif['Area'] == areas[i]].reset_index().drop('index', axis = 1) # Select the area\n",
    "\n",
    "    base_cv = run_cv_2(df_inuse.loc[[0]],i)\n",
    "    eval_cv = run_cv_2(df_inuse.loc[[1]],i)\n",
    "    \n",
    "    #used to get the precision and recall\n",
    "    print(areas[i],\"AD metric: \" + str(base_cv['Accuracy'].values))\n",
    "    print(areas[i],\"EvalOnly metric: \" +str(eval_cv['Accuracy'].values))\n",
    "\n",
    "    #print(areas[i], paired_ttest_2(base_cv,eval_cv)) # uncomment when comparing the models from same area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **11. Get coefficients**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ingenieria\n",
      "negocios\n",
      "estudioscreativos\n",
      "salud\n",
      "cienciassociales\n",
      "ambienteconstruido\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Model</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>CV Results</th>\n",
       "      <th>Variables</th>\n",
       "      <th>Coefficients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ingenieria</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.7256</td>\n",
       "      <td>[0.7165775401069518, 0.7058823529411765, 0.736...</td>\n",
       "      <td>[CalPromedioPrepa, Eva_ini_UMM1, Eva_ini_UMM2,...</td>\n",
       "      <td>[[0.6482572642354945, 0.23564007679801977, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negocios</td>\n",
       "      <td>LogReg</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.7034</td>\n",
       "      <td>[0.6422018348623854, 0.7064220183486238, 0.715...</td>\n",
       "      <td>[CalPromedioPrepa, Puntaje Seccion 8 Examen, P...</td>\n",
       "      <td>[[0.6936451310090773, 0.27687448870875303, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>estudioscreativos</td>\n",
       "      <td>XGB</td>\n",
       "      <td>{'learning_rate': [0.01], 'max_depth': [8], 'm...</td>\n",
       "      <td>0.6182</td>\n",
       "      <td>[0.6818181818181818, 0.5, 0.5454545454545454, ...</td>\n",
       "      <td>[Eva_ini_UMM2, Eva_ini_UMF1, Eva_ini_UMC1]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>salud</td>\n",
       "      <td>XGB</td>\n",
       "      <td>{'learning_rate': [0.05], 'max_depth': [8], 'm...</td>\n",
       "      <td>0.6648</td>\n",
       "      <td>[0.6666666666666666, 0.6666666666666666, 0.583...</td>\n",
       "      <td>[CalPromedioPrepa, enojo_n]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cienciassociales</td>\n",
       "      <td>NB</td>\n",
       "      <td>{'priors': [None]}</td>\n",
       "      <td>0.7199</td>\n",
       "      <td>[0.7619047619047619, 0.6666666666666666, 0.619...</td>\n",
       "      <td>[CalPromedioPrepa, Puntaje Seccion 21 Examen, ...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ambienteconstruido</td>\n",
       "      <td>NB</td>\n",
       "      <td>{'priors': [None]}</td>\n",
       "      <td>0.7542</td>\n",
       "      <td>[0.5833333333333334, 0.8333333333333334, 0.75,...</td>\n",
       "      <td>[CalPromedioPrepa, Eva_ini_UMF1, Eva_ini_UMM2,...</td>\n",
       "      <td>NOT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Area   Model  \\\n",
       "0          ingenieria  LogReg   \n",
       "0            negocios  LogReg   \n",
       "0   estudioscreativos     XGB   \n",
       "0               salud     XGB   \n",
       "0    cienciassociales      NB   \n",
       "0  ambienteconstruido      NB   \n",
       "\n",
       "                                          Parameters  Accuracy  \\\n",
       "0                                                 NA    0.7256   \n",
       "0                                                 NA    0.7034   \n",
       "0  {'learning_rate': [0.01], 'max_depth': [8], 'm...    0.6182   \n",
       "0  {'learning_rate': [0.05], 'max_depth': [8], 'm...    0.6648   \n",
       "0                                 {'priors': [None]}    0.7199   \n",
       "0                                 {'priors': [None]}    0.7542   \n",
       "\n",
       "                                          CV Results  \\\n",
       "0  [0.7165775401069518, 0.7058823529411765, 0.736...   \n",
       "0  [0.6422018348623854, 0.7064220183486238, 0.715...   \n",
       "0  [0.6818181818181818, 0.5, 0.5454545454545454, ...   \n",
       "0  [0.6666666666666666, 0.6666666666666666, 0.583...   \n",
       "0  [0.7619047619047619, 0.6666666666666666, 0.619...   \n",
       "0  [0.5833333333333334, 0.8333333333333334, 0.75,...   \n",
       "\n",
       "                                           Variables  \\\n",
       "0  [CalPromedioPrepa, Eva_ini_UMM1, Eva_ini_UMM2,...   \n",
       "0  [CalPromedioPrepa, Puntaje Seccion 8 Examen, P...   \n",
       "0         [Eva_ini_UMM2, Eva_ini_UMF1, Eva_ini_UMC1]   \n",
       "0                        [CalPromedioPrepa, enojo_n]   \n",
       "0  [CalPromedioPrepa, Puntaje Seccion 21 Examen, ...   \n",
       "0  [CalPromedioPrepa, Eva_ini_UMF1, Eva_ini_UMM2,...   \n",
       "\n",
       "                                        Coefficients  \n",
       "0  [[0.6482572642354945, 0.23564007679801977, 0.2...  \n",
       "0  [[0.6936451310090773, 0.27687448870875303, 0.1...  \n",
       "0                                                 []  \n",
       "0                                                 []  \n",
       "0                                                NOT  \n",
       "0                                                NOT  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "areas = ['ingenieria', 'negocios','estudioscreativos', 'salud', 'cienciassociales', 'ambienteconstruido'] # \n",
    "id_area = 0\n",
    "coeff_list = []\n",
    "\n",
    "areas_withsd = [1,1,0,1,1,1] #Based on the results above of statistical difference\n",
    "\n",
    "#Returns the experiment with admission data if there is significative diference between it and the evalcalnoprepa, if not it returns the one with less variables\n",
    "for i in range(6): #\n",
    "    #Get the data for the experiment\n",
    "    df_inuse = df_dif[df_dif['Area'] == areas[i]].reset_index().drop('index', axis = 1) # Select the area\n",
    "\n",
    "    base_cv = run_cv_2(df_inuse.loc[[0]],i,coef_flag = True)\n",
    "    eval_cv = run_cv_2(df_inuse.loc[[1]],i,coef_flag = True)\n",
    "    \n",
    "    if areas_withsd[i]:\n",
    "        coeff_list.append(base_cv)\n",
    "    else:\n",
    "        if len(base_cv['Variables'].values) < len(eval_cv['Variables'].values):\n",
    "            coeff_list.append(base_cv)\n",
    "        else:\n",
    "            coeff_list.append(eval_cv)\n",
    "\n",
    "    print(areas[i])\n",
    "    \n",
    "coefficients_df = pd.concat(coeff_list,axis =0)\n",
    "coefficients_df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients_df.to_csv(\"C:/Users/Milara/...\", encoding=\"ISO-8859-1\", index = False) #thus it is necessary to save it as the usual type of coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual extraction of feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:21:37] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "salud\n",
      "[\"['CalPromedioPrepa', 'enojo_n']\"]\n",
      "[0.34992912 0.6500709 ]\n"
     ]
    }
   ],
   "source": [
    "#Manual feature importances of XGB\n",
    "import pandas as pd\n",
    "\n",
    "#Read the file with the data of the best experiments\n",
    "df_coef = pd.read_csv(\"C:/Users/Milara/...\",encoding=\"ISO-8859-1\")\n",
    "\n",
    "areaCoeff = 'salud'#['estudioscreativos','salud']\n",
    "areaCoeff_id = 3 #[2,3]\n",
    "\n",
    "\n",
    "df_inuse = df_coef[df_coef['Area'] == areaCoeff]\n",
    "df_db = dflist_areas[areaCoeff_id]# Get the full database\n",
    "\n",
    "variables = df_inuse['Variables'].tolist()\n",
    "list_variables = string_2list(variables[0]) # get the list of variables to be used in the model\n",
    "#Clean the db with the selected variables\n",
    "data_samples = df_db.loc[:,list_variables]\n",
    "\n",
    "X = preprocessing.scale(data_samples)\n",
    "y = df_db['Binary_out']\n",
    "\n",
    "#params of estudios creativos {'learning_rate': [0.01], 'max_depth': [8], 'min_child_weight': [6], 'n_estimators': [100], 'random_state': [17], 'subsample': [0.5]}\n",
    "#params of salud              {'learning_rate': [0.05], 'max_depth': [8], 'min_child_weight': [6], 'n_estimators': [100], 'random_state': [17], 'subsample': [0.5]}\n",
    "\n",
    "xgb_print = xgb.XGBClassifier(learning_rate= 0.05, max_depth=  8, min_child_weight=  6, use_label_encoder = False, \n",
    "                              n_estimators=  100, random_state=  17, subsample= 0.5).fit(X, y)\n",
    "coefficients_xgb = xgb_print.feature_importances_\n",
    "\n",
    "print(areaCoeff)\n",
    "print(variables)\n",
    "print(coefficients_xgb)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
